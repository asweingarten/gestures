\documentclass{report}

\usepackage{fullpage}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{pdfpages}

\title{Smartwatch Gesture Recognition}
\date{\today}
\author{
  Lucas Wojciechowski \& Dane Carr \& Ariel Weingarten \\
  Group 15
}

\begin{document}

\maketitle

% The common requirement for all project is that the students in each group need to make use in their design project any method or combination of methods of material taught in the course (or closely related to it) to solve the proposed problem or improve on an existing solution. These are the required deliverables
% A report of 20 to 25 pages needs to be provided with these sections:

\chapter{Abstract}

% Abstract

\chapter{Problem Statement and Solution Motivation}
Wearable technology, such as smartwatches, are poised to become a ubiquitous consumer product. According to businessinsider.com, smartwatches sales are projected to reach 90 million units by 2018 (http://www.businessinsider.com/global-smartwatch-sales-set-to-explode-2014-3). Many user interface paradigms still need to be rethought for these devices to accommodate their small screens and limited input methods.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=90mm]{smartwatch.png}
  \caption{Smartwatch Annual Sales Projection \label{overflow}}
\end{figure}

Currently, these devices rely mostly on touch input and voice control. Touch input is usually effective, but due to the small form factor, a significant portion of the screen is often obscured by the user's finger. Voice control can be used to complete more complex actions that might be tedious to complete using only touch input, but voice commands are not always practical. They may be less effective in noisy environments, or users might feel uncomfortable using them in public places due to issues with privacy and social acceptance.

Hand and arm gestures could be used to augment existing input paradigms. Though less expressive than voice commands, hand and arm movements are relatively private and they are a natural way to communicate with the environment. There are presently no publicly available gesture recognition solutions for off-the-shelf smartwatches, though theories and interface ideas have been prototyped with other sensors such as Microsoft Kinect or custom ultra-sound detection systems. The potential applications of this technology are far-reaching, from seamless control of Internet-of-things devices to accessibility for visually impaired users.

We have acquired a LG G Watch R and a Nexus 5 phone to record gesture data via a simple, custom-built Android application. Data collected from the watch's accelerometer will be used to train a neural network to classify a set of simple gestures. We will compare the accuracy and performance of our classifier against similar gesture recognition systems in the research community.

\chapter{Theoretical Background Material}
Our work is inspired by two works in particular. First, there is the famous ``Learning Representations by Back-Propagating Errors" paper that first introduced the back propagation algorithm. Second, there is ``Gestures without Libraries, Toolkits, or Training: A \$1 Recognizer for User Interface Prototypes". The former lays the groundwork for our solution and the latter provided motivation for the problem domain.

\section{Backpropagation}

Backpropagation has become a common method for training neural networks. Before its formulation,  there was no way to provide a measure of accuracy for hidden layers in neural networks.

It is most often used in the supervised learning process as it requires the expected labeling for a set of inputs.  Before the formulation of this algorithm there

\section{\$1 Recognizer}s

% Theoretical background material with references

\chapter{Solution}

% Present your solution using tool(s) learned in class (or something related)

% TODO good transition from previous section
We set out to build a system which would allow us experiment with smartwatch gesture recognition.

As a research platform, this system was designed to be extensible, simple, and easy to work with. As a potential consumer platform, this system was built to be portable and permanent enough to run natively on Andorid smartphones.

Due to the lack of prior art in this space, we had to build some fundamental infrastructure ourselves, such as a data collection system and data repository for the smartwatch gesture sensor data.

In the end, the system we built consists of the following components
\begin{enumerate}
\item a set of gestures that were easy to perform by users and easy to recognize by our machine
\item a data collection app collected smartwatch sensor data from users performing our gestures
\item a repository of training and testing data sets from the collection app
\item a custom neural network implementation designed for performance and portability on Android smartphones
\item a testing harness which replayed the data to train and test a neural network for gesture recognition
\item a neural network topology optimizer based on genetic algorithms
\end{enumerate}

In the following subsections, we will discuss the requirements and implementation of each component in detail.

\section{Gesture Set}

% Which gestures worked and which gestures didn't work?

\section{Data Collection App}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=90mm]{app}
  \caption{Screenshot of Android smartwatch sensor data collection app}
\end{figure}

\section{Repository of Testing and Training Data}

\section{Neural Network Implementation}

\section{Testing Harness}

\section{Topology Optimizer}

% How did we determine the optimal toplogy?
% What was the optimal topology?
% What were the performance implications of larger / smaller toplogies

\chapter{Results}

\section{Codebase Metrics}

% How many lines of code do we have?

\section{Training Performance}

% CPU cost of training
% Number of data points needed to train system
% Difficulty of collecting data

\section{Classification Performance}

% Performance relative to the $1 Recognizer

\chapter{Conclusion}

% Conclusion

\chapter{References}
\begin{itemize}
\item Orr, Genevieve B. "Error Backpropagation." Error Backpropagation. Williamette University, n.d. Web. 02 Apr. 2015.
\item Rumelhart, D. E., Hinton, G. E., and Williams, R. J. Learning representations by back-propagating errors. Nature, 323, 533--536 [pdf]
\item Wobbrock, J.O., Wilson, A.D. and Li, Y. (2007). Gestures without libraries, toolkits or training: A \$1 recognizer for user interface prototypes. Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '07). Newport, Rhode Island (October 7-10, 2007). New York: ACM Press, pp. 159-168.

\end{itemize}
% References

\end{document}
